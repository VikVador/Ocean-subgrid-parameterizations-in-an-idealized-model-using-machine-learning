{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8531373-cd83-40d0-bbc2-28b641c208e6",
   "metadata": {},
   "source": [
    "<img src=\"assets/header_notebook.jpg\" />\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:2.5vw; color:#5A7D9F; font-weight:bold;\">\n",
    "    Ocean parameterizations in an idealized model using machine learning\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae3b7eac",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#5A7D9F;\">\n",
    "    Initialization\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one is able to load:\n",
    "</p>\n",
    "\n",
    "- All the librairies;\n",
    "\n",
    "- Basic functions used throughout the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5ae0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Librairies --\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import json\n",
    "import fsspec\n",
    "import xarray as xr\n",
    "import pyqg\n",
    "import pyqg.diagnostic_tools\n",
    "import src.pyqg_parameterization_benchmarks.coarsening_ops as coarsening\n",
    "\n",
    "from scipy.stats import gaussian_kde\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from src.pyqg_parameterization_benchmarks.utils import *\n",
    "from pyqg.diagnostic_tools import calc_ispec as _calc_ispec\n",
    "from src.pyqg_parameterization_benchmarks.neural_networks import FullyCNN\n",
    "from src.pyqg_parameterization_benchmarks.neural_networks import FCNNParameterization\n",
    "from src.pyqg_parameterization_benchmarks.online_metrics import diagnostic_differences\n",
    "\n",
    "# You can use the magic function %matplotlib inline to enable the inline plotting, \n",
    "# where the plots/graphs will be displayed just below the cell where your plotting commands are written. \n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "# Making sure modules are reloaded when modified\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aba60e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Functions --\n",
    "#\n",
    "# Used to compute the power spectrum\n",
    "calc_ispec = lambda *args, **kwargs: _calc_ispec(*args, averaging = False, truncate =False, **kwargs)\n",
    "\n",
    "def get_dataset(index, base_url = \"https://g-402b74.00888.8540.data.globus.org\"):\n",
    "    \"\"\"\n",
    "    Documentation\n",
    "    -------------\n",
    "    Load the datasets used in L. Zanna & Al.'s paper  are hosted on globus as zarr files\n",
    "    \"\"\"\n",
    "    paths = ['eddy/high_res', 'eddy/low_res', 'jet/high_res', 'jet/low_res', 'eddy/forcing1', 'eddy/forcing2', 'eddy/forcing3', 'eddy/low_res']\n",
    "    mapper = fsspec.get_mapper(f\"{base_url}/{paths[index]}.zarr\")\n",
    "    return xr.open_zarr(mapper, consolidated=True)\n",
    "\n",
    "def run_save(model, sampling_freq = 1000):\n",
    "    \"\"\"\n",
    "    Documentation\n",
    "    -------------\n",
    "    Saves simulation results every iterations % sampling_freq == 0 and \n",
    "    concatenates everything into a huge xarray dataset.\n",
    "    \"\"\"\n",
    "    # Run the model and save snapshots\n",
    "    snapshots = []\n",
    "    while model.t < model.tmax:\n",
    "        if model.tc % sampling_freq == 0:\n",
    "            snapshots.append(model.to_dataset().copy(deep = True))\n",
    "        model._step_forward()\n",
    "\n",
    "    # Concatenation of all the results into a big dataset\n",
    "    ds = xr.concat(snapshots, dim = 'time')\n",
    "\n",
    "    # Diagnostics get dropped by this procedure since they're only present for\n",
    "    # part of the timeseries; resolve this by saving the most recent\n",
    "    # diagnostics (they're already time-averaged so this is ok)\n",
    "    for k,v in snapshots[-1].variables.items():\n",
    "        if k not in ds:\n",
    "            ds[k] = v.isel(time=-1)\n",
    "\n",
    "    # Drop complex variables since they're redundant and can't be saved\n",
    "    complex_vars = [k for k,v in ds.variables.items() if np.iscomplexobj(v)]\n",
    "    ds = ds.drop_vars(complex_vars)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ca3dfe7",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#5A7D9F;\">\n",
    "    PYQG - Generating & Saving\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "</p>\n",
    "\n",
    "- Generate a **high resolution** simulation from a quasi-geostrophic model (PYQG). \n",
    "\n",
    "- Afterwards, the corresponding **low resolution** simulation will be created using one of the operators (filtering and coarsening) created by L. Zanne & Al.. \n",
    "\n",
    "- Finally, the datasets will be **saved onto the hard drive**. \n",
    "<p align=\"justify\">\n",
    "    <b>Note</b> <br><br>\n",
    "    - Eddies and Jets simulation are the exact one used by L. Zanne & Al. in their paper.\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26779925",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "<p align=\"center\">\n",
    "\t<b style=\"font-size:1vw;\">\n",
    "\tSimulation type\n",
    "\t</b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "<table style=\"width: 100%;\" border=\"1\">\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"width: 15%;\" align=\"center\"><b>INDEX</b></td>\n",
    "\t\t\t<td style=\"width: 13%;\" align=\"center\">0</td>\n",
    "\t\t\t<td style=\"width: 13%;\" align=\"center\">1</td>\n",
    "\t\t\t<td style=\"width: 15%;\" align=\"center\">2</td>\n",
    "\t\t\t<td style=\"width: 15%;\" align=\"center\">3</td>\n",
    "\t\t\t<td style=\"width: 16%;\" align=\"center\">4</td>\n",
    "\t\t\t<td style=\"width: 18%;\" align=\"center\">5</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"width: 15%;\"align=\"center\"><b>TYPE</b></td>\n",
    "\t\t\t<td style=\"width: 13%;\" align=\"center\">Eddies</td>\n",
    "\t\t\t<td style=\"width: 13%;\" align=\"center\">Jets  </td>\n",
    "\t\t\t<td style=\"width: 15%;\" align=\"center\">Eddies (Debug)</td>\n",
    "\t\t\t<td style=\"width: 15%;\" align=\"center\">Jets   (Debug)</td>\n",
    "\t\t\t<td style=\"width: 16%;\" align=\"center\">Eddies (Random)</td>\n",
    "\t\t\t<td style=\"width: 18%;\" align=\"center\">Jets (Random)</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "<p align=\"center\">\n",
    "\t<b style=\"font-size:1vw;\">\n",
    "\tParameters\n",
    "\t</b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "<table style=\"width: 100%;\" border=\"1\">\n",
    "\t<tbody>\n",
    "\t\t<tr style=\"height: 21px;\">\n",
    "\t\t\t<td style=\"width: 16%;\" align=\"center\"><b>PARAMETERS</b></td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">nx</td>\n",
    "\t\t\t<td style=\"width: 10%;\" align=\"center\">dt</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">tmax</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">tavestart</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">rek</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">Δ</td>\n",
    "\t\t\t<td style=\"width: 14%;\" align=\"center\">β</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr style=\"height: 21.5px;\">\n",
    "\t\t\t<td style=\"width: 16%;\" align=\"center\"><b>DESCRIPTION</b></td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">Number of real space grid points in the x directions</td>\n",
    "\t\t\t<td style=\"width: 10%;\" align=\"center\">Numerical timestep (in hours)</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">Total time of integration (in years)</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">Start time for averaging (in years)</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">Linear drag in lower layer</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">Layer thickness ratio (H1/H2)</td>\n",
    "\t\t\t<td style=\"width: 14%;\" align=\"center\">Gradient of coriolis parameter.</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr style=\"height: 21.5px;\">\n",
    "\t\t\t<td style=\"width: 16%;\" align=\"center\"><b>EDDIES</b></td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">256</td>\n",
    "\t\t\t<td style=\"width: 10%;\" align=\"center\">1</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">10</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">5</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">5.789e-7</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">0.25</td>\n",
    "\t\t\t<td style=\"width: 14%;\" align=\"center\">1.5 * 1e-11</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr style=\"height: 21px;\">\n",
    "\t\t\t<td style=\"width: 16%;\" align=\"center\"><b>JETS</b></td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">256</td>\n",
    "\t\t\t<td style=\"width: 10%;\" align=\"center\">1</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">10</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">5</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">7e-08</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">0.1</td>\n",
    "\t\t\t<td style=\"width: 14%;\" align=\"center\">1e-11</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr style=\"height: 21.5px;\">\n",
    "\t\t\t<td style=\"width: 16%;\" align=\"center\"><b>EDDIES (Debug)</b></td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">256</td>\n",
    "\t\t\t<td style=\"width: 10%;\" align=\"center\">1</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">2</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">1</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">5.789e-7</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">0.25</td>\n",
    "\t\t\t<td style=\"width: 14%;\" align=\"center\">1.5 * 1e-11</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr style=\"height: 21px;\">\n",
    "\t\t\t<td style=\"width: 16%;\" align=\"center\"><b>JETS (Debug)</b></td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">256</td>\n",
    "\t\t\t<td style=\"width: 10%;\" align=\"center\">1</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">2</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">1</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">7e-08</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">0.1</td>\n",
    "\t\t\t<td style=\"width: 14%;\" align=\"center\">1e-11</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr style=\"height: 21.5px;\">\n",
    "\t\t\t<td style=\"width: 16%;\" align=\"center\"><b>EDDIES (Random)</b></td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">256</td>\n",
    "\t\t\t<td style=\"width: 10%;\" align=\"center\">1</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">10</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">5</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">[5.7, 5.9] * 1e-7</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">0.25</td>\n",
    "\t\t\t<td style=\"width: 14%;\" align=\"center\">[1.45, 1.55] * 1e-11</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr style=\"height: 21px;\">\n",
    "\t\t\t<td style=\"width: 16%;\" align=\"center\"><b>JETS (Random)</b></td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">256</td>\n",
    "\t\t\t<td style=\"width: 10%;\" align=\"center\">1</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">10</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">5</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">[6.9, 7.1] * 1e-8</td>\n",
    "\t\t\t<td style=\"width: 12%;\" align=\"center\">0.1</td>\n",
    "\t\t\t<td style=\"width: 14%;\" align=\"center\">[0.95, 1.05] * 1e-11</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "<p align=\"center\">\n",
    "\t<b style=\"font-size:1vw;\">\n",
    "\tCoarsening operators\n",
    "\t</b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "<table style=\"width: 100%;\" border=\"1\">\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"width: 10%;\" align=\"center\"><b>OPERATOR</b></td>\n",
    "\t\t\t<td style=\"width: 15%;\" align=\"center\">&nbsp;1</td>\n",
    "\t\t\t<td style=\"width: 15%;\" align=\"center\">&nbsp;2</td>\n",
    "\t\t\t<td style=\"width: 17%;\" align=\"center\">3</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td style=\"width: 10%;\"align=\"center\"><b>DESCRIPTION</b></td>\n",
    "\t\t\t<td style=\"width: 15%;\"align=\"center\">Spectral Truncation, Sharp Filter</td>\n",
    "\t\t\t<td style=\"width: 15%;\"align=\"center\">Spectral Truncation, Gaussian Filter</td>\n",
    "\t\t\t<td style=\"width: 17%;\"align=\"center\">GCM Filter, Averaging and Coarsening</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "980190e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which simulation type to use to generate the high resolution data\n",
    "simulation_type = 0\n",
    "\n",
    "# Define at which frequency to save the results (Ex: if sampling = 1, each hour the data is saved)\n",
    "sampling_frequency = 8\n",
    "\n",
    "# Define which operator to apply on the high resolution data\n",
    "operator_index = 1\n",
    "\n",
    "# Define the size of the dataset that will be used as training data\n",
    "train_size = 0.7\n",
    "\n",
    "# Define if the high resolution training set should be saved entirely or just the last sample (/!\\ High memory cost if True)\n",
    "save_HR_train = False\n",
    "\n",
    "# Define the name of the folder used to save the datasets (../datasets/save_folder)\n",
    "save_folder = \"eddies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e74be9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Functions -- \n",
    "#\n",
    "#\n",
    "def train_test_split_xarray(dataset, train_size = 0.7):\n",
    "\n",
    "    # Retreiving the size of the time dimension of the xarray\n",
    "    size        = dataset.dims[\"time\"]\n",
    "\n",
    "    # Computing indexes for training and testing sets\n",
    "    index_train_start = 0\n",
    "    index_train_end   = int(size * train_size)\n",
    "    index_test_start  = index_train_end + 1\n",
    "    index_test_end    = size - 1\n",
    "\n",
    "    # Creating slicing vectors\n",
    "    train_indexes = list(np.linspace(index_train_start, index_train_end, num = index_train_end + 1, dtype = int))\n",
    "    test_indexes  = list(np.linspace(index_test_start,  index_test_end , num = index_test_end - index_test_start, dtype = int))\n",
    "\n",
    "    # Creation of the datasets\n",
    "    dataset_train = dataset.isel(time = train_indexes)\n",
    "    dataset_test  = dataset.isel(time = test_indexes)\n",
    "\n",
    "    return dataset_train, dataset_test\n",
    "\n",
    "def getDataset(model_LOW_RESOLUTION):\n",
    "\n",
    "    # Initial dataset (everything will be added to it)\n",
    "    dataset_LOW_RESOLUTION_base = model_LOW_RESOLUTION.m2.to_dataset().copy(deep = True)\n",
    "\n",
    "    # Retreiving each corresponding variables\n",
    "    dqdt_bar, dqbar_dt, q_tot = model_LOW_RESOLUTION.q_forcing_total\n",
    "    q_sfor                    = model_LOW_RESOLUTION.subgrid_forcing(\"q\")\n",
    "    u_sfor                    = model_LOW_RESOLUTION.subgrid_forcing(\"u\")\n",
    "    v_sfor                    = model_LOW_RESOLUTION.subgrid_forcing(\"v\")\n",
    "    uq_sf, vq_sf              = model_LOW_RESOLUTION.subgrid_fluxes(\"q\")\n",
    "    uu_sf, vu_sf              = model_LOW_RESOLUTION.subgrid_fluxes(\"u\")\n",
    "    uv_sf, vv_sf              = model_LOW_RESOLUTION.subgrid_fluxes(\"v\")\n",
    "\n",
    "    # Creation of dataset with missing values\n",
    "    missing_values = {\n",
    "                        \"q_forcing_total\"   : ((\"lev\", \"x\", \"y\"), q_tot),\n",
    "                        \"dqdt_bar\"          : ((\"lev\", \"x\", \"y\"), dqdt_bar),\n",
    "                        \"dqbar_dt\"          : ((\"lev\", \"x\", \"y\"), dqbar_dt),\n",
    "                        \"q_subgrid_forcing\" : ((\"lev\", \"x\", \"y\"), q_sfor),\n",
    "                        \"u_subgrid_forcing\" : ((\"lev\", \"x\", \"y\"), u_sfor),\n",
    "                        \"v_subgrid_forcing\" : ((\"lev\", \"x\", \"y\"), v_sfor),\n",
    "                        \"uq_subgrid_flux\"   : ((\"lev\", \"x\", \"y\"), uq_sf),\n",
    "                        \"vq_subgrid_flux\"   : ((\"lev\", \"x\", \"y\"), vq_sf),\n",
    "                        \"uu_subgrid_flux\"   : ((\"lev\", \"x\", \"y\"), uu_sf),\n",
    "                        \"vv_subgrid_flux\"   : ((\"lev\", \"x\", \"y\"), vv_sf),\n",
    "                        \"uv_subgrid_flux\"   : ((\"lev\", \"x\", \"y\"), uv_sf)}\n",
    "\n",
    "    dataset_LOW_RESOLUTION_missing = xr.Dataset(missing_values)\n",
    "\n",
    "    # Merging all the results    \n",
    "    return xr.merge([dataset_LOW_RESOLUTION_base, dataset_LOW_RESOLUTION_missing])\n",
    "\n",
    "def run_simulations(model_HIGH_RESOLUTION, coarsening_index, sampling_freq = 1000):\n",
    "    \"\"\"\n",
    "    Documentation\n",
    "    -------------\n",
    "    Saves simulation results at a frequency defined by the sampling frequency.\n",
    "    \"\"\"\n",
    "    # Used to store high and low resolution data\n",
    "    snapshots_HIGH_RESOLUTION, snapshots_LOW_RESOLUTION = list(), list()\n",
    "\n",
    "    # Stores the low resolution model\n",
    "    model_LOW_RESOLUTION = 1\n",
    "\n",
    "    # Running the simulation\n",
    "    while model_HIGH_RESOLUTION.t < model_HIGH_RESOLUTION.tmax:\n",
    "\n",
    "        if model_HIGH_RESOLUTION.tc % sampling_freq == 0:\n",
    "\n",
    "            # Saving high resolution data\n",
    "            snapshots_HIGH_RESOLUTION.append(model_HIGH_RESOLUTION.to_dataset().copy(deep = True))\n",
    "\n",
    "            # Creation of the coarsened data\n",
    "            if coarsening_index   == 1:\n",
    "                model_LOW_RESOLUTION = coarsening.Operator1(model_HIGH_RESOLUTION, low_res_nx = 64) # Spectral truncation + sharp filter\n",
    "            elif coarsening_index == 2:\n",
    "                model_LOW_RESOLUTION = coarsening.Operator2(model_HIGH_RESOLUTION, low_res_nx = 64) # Spectral truncation + sharp filter\n",
    "            elif coarsening_index == 3:\n",
    "                model_LOW_RESOLUTION = coarsening.Operator3(model_HIGH_RESOLUTION, low_res_nx = 64) # GCM-Filters + real-space coarsening\n",
    "            else:\n",
    "                print(\"ERROR - Operator index is invalid !\")\n",
    "\n",
    "            # Saving low resolution data\n",
    "            snapshots_LOW_RESOLUTION.append(getDataset(model_LOW_RESOLUTION))\n",
    "\n",
    "        # Computing next step of simulation\n",
    "        model_HIGH_RESOLUTION._step_forward()\n",
    "\n",
    "    # Concatenation of all the results into a big dataset\n",
    "    ds_HR = xr.concat(snapshots_HIGH_RESOLUTION, dim = 'time')\n",
    "    ds_LR = xr.concat(snapshots_LOW_RESOLUTION,  dim = 'time')\n",
    "\n",
    "    print(ds_HR)\n",
    "    \n",
    "    # Diagnostics get dropped by this procedure since they're only present for part of the timeseries; \n",
    "    # resolve this by saving the most recent diagnostics (they're already time-averaged so this is ok)\n",
    "    for k, v in snapshots_HIGH_RESOLUTION[-1].variables.items():\n",
    "        if k not in ds_HR:\n",
    "            ds_HR[k] = v.isel(time = -1)\n",
    "\n",
    "    for k,v in snapshots_LOW_RESOLUTION[-1].variables.items():\n",
    "        if k not in ds_LR:\n",
    "            ds_LR[k] = v.isel(time = -1)\n",
    "\n",
    "    # Drop complex variables since they're redundant and can't be saved\n",
    "    complex_vars = [k for k,v in ds_HR.variables.items() if np.iscomplexobj(v)]\n",
    "    ds_HR = ds_HR.drop_vars(complex_vars)\n",
    "    \n",
    "    complex_vars = [k for k,v in ds_LR.variables.items() if np.iscomplexobj(v)]\n",
    "    ds_LR = ds_LR.drop_vars(complex_vars)\n",
    "\n",
    "    return ds_HR, ds_LR, model_LOW_RESOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a80cf859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- RUNNING SIMULATION --\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# -- Generating --\n",
    "#\n",
    "# Definition of the parameters for each simulation type\n",
    "nx        = [256        , 256   , 256        , 256  ,  256, 256]\n",
    "dt        = [1          , 1     , 1          , 1    ,    1,   1]\n",
    "tmax      = [10         , 10    , 2          , 2    ,   10,  10]\n",
    "tavestart = [5          , 5     , 1          , 1    ,    5,   5]\n",
    "rek       = [5.789e-7   , 7e-08 , 5.789e-7   , 7e-08,   -1,  -1]\n",
    "delta     = [0.25       , 0.1   , 0.25       , 0.1  , 0.25, 0.1]\n",
    "beta      = [1.5 * 1e-11, 1e-11 , 1.5 * 1e-11, 1e-11,   -1,  -1]\n",
    "\n",
    "# Radom parameter values\n",
    "rek_random  = random.uniform(5.7, 5.9)   * 1e-7  if simulation_type < 5 else \\\n",
    "              random.uniform(6.9, 7.1)   * 1e-8\n",
    "\n",
    "beta_random = random.uniform(1.45, 1.55) * 1e-11 if simulation_type < 5 else \\\n",
    "              random.uniform(0.95, 1.05) * 1e-11\n",
    "\n",
    "# Creation of dictionnary (Conversion to seconds embedded)\n",
    "simulation_parameters_training              = {}\n",
    "simulation_parameters_training['nx']        = nx       [simulation_type]\n",
    "simulation_parameters_training['dt']        = dt       [simulation_type] * 60 * 60\n",
    "simulation_parameters_training['tmax']      = tmax     [simulation_type] * 24 * 60 * 60 * 360\n",
    "simulation_parameters_training['tavestart'] = tavestart[simulation_type] * 24 * 60 * 60 * 360\n",
    "simulation_parameters_training['rek']       = rek      [simulation_type] if simulation_type < 4 else rek_random\n",
    "simulation_parameters_training['delta']     = delta    [simulation_type]\n",
    "simulation_parameters_training['beta']      = beta     [simulation_type] if simulation_type < 4 else beta_random\n",
    "\n",
    "# Creation of a PYQG model with corresponding parameters\n",
    "model_HIGH_RESOLUTION = pyqg.QGModel(**simulation_parameters_training)\n",
    "\n",
    "# Creation of the associated dataset\n",
    "dataset_HIGH_RESOLUTION, dataset_LOW_RESOLUTION, model_LOW_RESOLUTION = run_simulations(model_HIGH_RESOLUTION, \n",
    "                                                                                        operator_index, \n",
    "                                                                                        sampling_freq = sampling_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f867f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Saving --\n",
    "#\n",
    "# Complete path to saving folder\n",
    "saving_path = \"../datasets/\" + save_folder\n",
    "\n",
    "# Checks if the saving folder exists, if not, creates it\n",
    "if not os.path.exists(saving_path):\n",
    "   os.makedirs(saving_path)\n",
    "\n",
    "# Generating training and test sets\n",
    "train_HR, test_HR = train_test_split_xarray(dataset_HIGH_RESOLUTION, train_size = train_size)\n",
    "train_LR, test_LR = train_test_split_xarray(dataset_LOW_RESOLUTION,  train_size = train_size)\n",
    "\n",
    "# Saving the datasets\n",
    "train_LR.to_netcdf(saving_path + \"/train_LR.nc\")\n",
    "test_HR.to_netcdf( saving_path + \"/test_HR.nc\" )\n",
    "test_LR.to_netcdf( saving_path + \"/test_LR.nc\" )\n",
    "\n",
    "# In order to simply observe what is inside the training set, the last sample is uniquely saved (in order to save space).\n",
    "# However, one has still the possibility to save the entire dataset if needed.\n",
    "train_HR.to_netcdf(saving_path + \"/train_HR.nc\") if save_HR_train == True else \\\n",
    "   train_HR.isel(time = [-1]).copy(deep = True).to_netcdf(saving_path + \"/train_HR.nc\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce254a1b",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#5A7D9F;\">\n",
    "    PYQG - Loading\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7df261fb",
   "metadata": {},
   "source": [
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "</p>\n",
    "\n",
    "- **Load** a **high resolution** simulation and its corresponding **low resolution** dataset saved on a hard drive.\n",
    "\n",
    "- Observe the distribution of quantities such as **energy** and **enstrophy**.\n",
    "\n",
    "**Energy budget (should sum to 0):**\n",
    "- `KEflux`: how kinetic energy is being transferred across lengthscales\n",
    "- `APEflux`: how available potential energy is being transferred across lengthscales\n",
    "- `APEgenspec`: how much new available potential energy is being generated at each scale\n",
    "- `KEfrictionspec`: how much energy is being lost to bottom drag at each lengthscale\n",
    "- `Dissspec`: how much energy is being lost due to numerical dissipation at each lengthscale\n",
    "\n",
    "**Enstrophy budget (should sum to 0):**\n",
    "- `ENSflux`: how enstrophy is being transferred across lengthscales\n",
    "- `ENSgenspec`: how much new enstrophy is being generated\n",
    "- `ENSfrictionspec`: how much enstrophy is lost to bottom drag\n",
    "- `ENSDissspec`: how much enstrophy is lost to numerical dissipation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae9a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the folder from which to load the datasets\n",
    "loading_folder_data = \"eddies_debug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d15918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Loading datasets --\n",
    "#\n",
    "loading_path = \"../datasets/\" + loading_folder_data\n",
    "\n",
    "# Security\n",
    "if not os.path.exists(loading_path):\n",
    "   print(\"ERROR - The loading folder does not exist\")\n",
    "\n",
    "train_HR = xr.open_dataset(loading_path + \"/train_HR.nc\")\n",
    "test_HR  = xr.open_dataset(loading_path + \"/test_HR.nc\" )\n",
    "train_LR = xr.open_dataset(loading_path + \"/train_LR.nc\")\n",
    "test_LR  = xr.open_dataset(loading_path + \"/test_LR.nc\" )\n",
    "\n",
    "# Displaying information\n",
    "print(\"Train HR = \" + str(train_HR.dims[\"time\"]))\n",
    "print(\"Test  HR = \" + str(test_HR.dims[\"time\"]))\n",
    "print(\"Train LR = \" + str(train_LR.dims[\"time\"]))\n",
    "print(\"Test  LR = \" + str(test_LR.dims[\"time\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b61cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c29943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Energy Budget --\n",
    "energy_budget = ['KEflux','APEflux','APEgenspec','KEfrictionspec','Dissspec']\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.title(f\"High Resolution ({loading_folder_data}) - Energy Budget\")\n",
    "plt.axhline(0,color='gray', ls='--')\n",
    "for term in energy_budget:\n",
    "    plt.semilogx(test_HR.k, test_HR[term].sum('l'), label=term) \n",
    "plt.semilogx(test_HR.k, np.sum([test_HR[t].sum('l') for t in energy_budget], axis=0), label='Residual')\n",
    "plt.legend()\n",
    "plt.ylabel(\"Energy transfer $[m^2 s^{-3}]$\")\n",
    "plt.xlabel(\"Zonal wavenumber $[m^{-1}]$\")\n",
    "plt.show()\n",
    "\n",
    "# Complete path to save the figure\n",
    "save_path_complete_energy = f\"../datasets/{loading_folder_data}/diagnostic_variables\"\n",
    "\n",
    "# Check if image folder exists\n",
    "if not os.path.exists(save_path_complete_energy):\n",
    "    os.makedirs(save_path_complete_energy)\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(save_path_complete_energy + f\"/energy_budget.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aecaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Enstrophy Budget --\n",
    "enstrophy_budget = ['ENSflux','ENSgenspec','ENSfrictionspec','ENSDissspec']\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "plt.title(f\"High Resolution ({loading_folder_data}) - Enstrophy Budget\")\n",
    "plt.axhline(0,color='gray', ls='--')\n",
    "for term in enstrophy_budget:\n",
    "    plt.semilogx(test_HR.k, test_HR[term].sum('l'), label=term) \n",
    "plt.semilogx(test_HR.k, np.sum([test_HR[t].sum('l') for t in enstrophy_budget], axis=0), label='Residual')\n",
    "plt.legend()\n",
    "plt.ylabel(\"Enstrophy transfer $[s^{-3}]$\")\n",
    "plt.xlabel(\"Zonal wavenumber $[m^{-1}]$\")\n",
    "plt.show()\n",
    "\n",
    "# Complete path to save the figure\n",
    "save_path_complete_energy = f\"../datasets/{loading_folder_data}/diagnostic_variables\"\n",
    "\n",
    "# Check if image folder exists\n",
    "if not os.path.exists(save_path_complete_energy):\n",
    "    os.makedirs(save_path_complete_energy)\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(save_path_complete_energy + f\"/enstrophy_budget.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43376e7c",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#5A7D9F;\">\n",
    "    PYQG - Dataset exploration (high and low resolution)\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to observe graphically one of the following variables:\n",
    "</p>\n",
    "\n",
    "- **State variables**\n",
    "\n",
    "<table style=\"width: 100%;\">\n",
    "\t<tbody>\n",
    "\t\t<tr>\n",
    "\t\t\t<td width=\"12%;\" align=\"center\">q</td>\n",
    "\t\t\t<td width=\"15%;\" align=\"center\">u</td>\n",
    "\t\t\t<td width=\"15%;\" align=\"center\">v</td>\n",
    "\t\t\t<td width=\"15%;\" align=\"center\">ufull</td>\n",
    "\t\t\t<td width=\"15%;\" align=\"center\">vfull</td>\n",
    "\t\t\t<td width=\"23%;\" align=\"center\">streamfunction - Ψ (NW)</td>\n",
    "\t\t</tr>\n",
    "\t\t<tr>\n",
    "\t\t\t<td align=\"center\">Potential vorcitity</td>\n",
    "\t\t\t<td align=\"center\">x-velocity relative to the background flow</td>\n",
    "\t\t\t<td align=\"center\">y-velocity relative to the background flow</td>\n",
    "\t\t\t<td align=\"center\">x-velocity with the background flow </td>\n",
    "\t\t\t<td align=\"center\">y-velocity with the background flow </td>\n",
    "\t\t\t<td align=\"center\">A particular case of a vector potential of velocity , related to velocity by the equality</td>\n",
    "\t\t</tr>\n",
    "\t</tbody>\n",
    "</table>\n",
    "\n",
    "- **Subgrid forcing variables**\n",
    "\n",
    "| Forcing | q | u | v |\n",
    "|---| :----: | :----: | :----: |\n",
    "| Equation | $S_q \\equiv \\overline{(\\mathbf{u} \\cdot \\nabla)q} - (\\overline{\\mathbf{u}} \\cdot \\overline{\\nabla})\\overline{q}$ | $S_u \\equiv \\overline{(\\mathbf{u} \\cdot \\nabla)u} - (\\overline{\\mathbf{u}} \\cdot \\overline{\\nabla})\\overline{u}$ | $S_v \\equiv \\overline{(\\mathbf{u} \\cdot \\nabla)v} - (\\overline{\\mathbf{u}} \\cdot \\overline{\\nabla})\\overline{v}$ |\n",
    "\n",
    "<br/>\n",
    "\n",
    "- **Subgrid flux variables**\n",
    "\n",
    "| Flux | uq | vq | uu | vv | uv |\n",
    "|---|:----:|:----:|:----:|:----:|:----:|\n",
    "| Equations | $\\phi_{uq} \\equiv \\overline{uq} - \\bar{u}\\bar{q}$ | $\\phi_{vq} \\equiv \\overline{vq} - \\bar{v}\\bar{q}$ | $\\phi_{uu} \\equiv \\overline{u^2} - \\bar{u}^2$ | $\\phi_{vv} \\equiv \\overline{v^2} - \\bar{v}^2$ | $\\phi_{uv} \\equiv \\overline{uv} - \\bar{u}\\bar{v}$ |\n",
    "\n",
    "<br/>\n",
    "\n",
    "- **Other variables**\n",
    "\n",
    "| Flux | dqdt_bar | dqbar_dt |\n",
    "|---|:----:|:----:|\n",
    "| Information |  PV tendency from the high-resolution model, filtered and coarsened to low resolution | PV tendency from the low-resolution model,  initialized at $\\overline{q}$|\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "- *Note*\n",
    "\n",
    "\t- $\\nabla \\cdot \\langle\\phi_{uq}, \\phi_{vq}\\rangle = S_q$;\n",
    "\n",
    "\t- $\\nabla \\cdot \\langle\\phi_{uu}, \\phi_{uv}\\rangle = S_u$ and $\\nabla \\cdot \\langle\\phi_{uv}, \\phi_{vv}\\rangle = S_v$;\n",
    "\n",
    "\t- dqdt_bar - dqbar_dt can be an alternative to $S_q$ (it's very similar, except it also accounts for numerical dissipation).\n",
    "\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "<p align=\"center\">\n",
    "\t<b style=\"font-size:1vw;\">\n",
    "\tFunctions\n",
    "\t</b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f34f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Functions (State variables) --\n",
    "#\n",
    "# Allows to display easily an image (from coarsening notebook)\n",
    "def imshow(arr, vlim = 3e-5):\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    return plt.imshow(arr, vmin = -vlim, vmax = vlim, cmap = 'bwr', interpolation = 'none')\n",
    "\n",
    "# Used to plot easily a state variable\n",
    "def plotStateVariable(high_res, low_res, state_variable = \"q\", save_path = \"\"):\n",
    "\n",
    "    # Text for the caption\n",
    "    caption = [\"Upper Level : z = 1\", \"Lower Level : z = 2\"]\n",
    "\n",
    "    # Looping over the levels\n",
    "    for l in range(2):\n",
    "\n",
    "        # Initialization of the plot\n",
    "        fig = plt.figure(figsize=(21, 6))\n",
    "\n",
    "        # Plotting the state variables (Note: in the coarsening class, the original high resolution model is stored in m1 !)\n",
    "        if state_variable == \"q\":\n",
    "\n",
    "            # High resolution\n",
    "            plt.subplot(1, 2, 1)\n",
    "            high_res.q.isel(lev = l, time = -1).plot()\n",
    "\n",
    "            # Low resolution\n",
    "            plt.subplot(1, 2, 2)\n",
    "            low_res.q.isel(lev = l, time = -1).plot()\n",
    "\n",
    "            # Adding a caption to the plot\n",
    "            fig.text(0.45, -0.1, f\"$Figure$: Representation of the potential vorticity q for the high resolution (left) and low resolution simulations (right) - {caption[l]}\", ha = 'center')\n",
    "\n",
    "        elif state_variable == \"u\":\n",
    "\n",
    "            # High resolution\n",
    "            plt.subplot(1, 2, 1)\n",
    "            high_res.u.isel(lev = l, time = -1).plot()\n",
    "\n",
    "            # Low resolution\n",
    "            plt.subplot(1, 2, 2)\n",
    "            low_res.u.isel(lev = l, time = -1).plot()\n",
    "\n",
    "            # Adding a caption to the plot\n",
    "            fig.text(0.45, -0.1, f\"$Figure$: Representation of the horizontal velocity u for the high resolution (left) and low resolution simulations (right) - {caption[l]}\", ha = 'center')\n",
    "\n",
    "        elif state_variable == \"v\":\n",
    "                    \n",
    "            # High resolution\n",
    "            plt.subplot(1, 2, 1)\n",
    "            high_res.v.isel(lev = l, time = -1).plot()\n",
    "\n",
    "            # Low resolution\n",
    "            plt.subplot(1, 2, 2)\n",
    "            low_res.v.isel(lev = l, time = -1).plot()\n",
    "\n",
    "            # Adding a caption to the plot\n",
    "            fig.text(0.45, -0.1, f\"$Figure$: Representation of the vertical velocity y for the high resolution (left) and low resolution simulations (right) - {caption[l]}\", ha = 'center')\n",
    "\n",
    "        elif state_variable == \"ufull\":\n",
    "                    \n",
    "            # High resolution\n",
    "            plt.subplot(1, 2, 1)\n",
    "            high_res.ufull.isel(lev = l, time = -1).plot()\n",
    "\n",
    "            # Low resolution\n",
    "            plt.subplot(1, 2, 2)\n",
    "            low_res.ufull.isel(lev = l, time = -1).plot()\n",
    "\n",
    "            # Adding a caption to the plot\n",
    "            fig.text(0.45, -0.1, f\"$Figure$: Representation of the horizontal velocity u with background flow for the high resolution (left) and low resolution simulations (right) - {caption[l]}\", ha = 'center')\n",
    "\n",
    "\n",
    "        elif state_variable == \"vfull\":\n",
    "                    \n",
    "            # High resolution\n",
    "            plt.subplot(1, 2, 1)\n",
    "            high_res.vfull.isel(lev = l, time = -1).plot()\n",
    "\n",
    "            # Low resolution\n",
    "            plt.subplot(1, 2, 2)\n",
    "            low_res.vfull.isel(lev = l, time = -1).plot()\n",
    "\n",
    "            # Adding a caption to the plot\n",
    "            fig.text(0.45, -0.1, f\"$Figure$: Representation of the vertical velocity v with background flow for the high resolution (left) and low resolution simulations (right) - {caption[l]}\", ha = 'center')\n",
    "\n",
    "\n",
    "        elif state_variable == \"streamfunction\":\n",
    "                    \n",
    "            # High resolution\n",
    "            plt.subplot(1, 2, 1)\n",
    "            high_res.streamfunction.isel(lev = l, time = -1).plot()\n",
    "\n",
    "            # Low resolution\n",
    "            plt.subplot(1, 2, 2)\n",
    "            low_res.streamfunction.isel(lev = l, time = -1).plot()\n",
    "\n",
    "            # Adding a caption to the plot\n",
    "            fig.text(0.45, -0.1, f\"$Figure$: Representation of the streamfunction for the high resolution (left) and low resolution simulations (right) - {caption[l]}\", ha = 'center')\n",
    "\n",
    "        if save_path not in [\"\"]:\n",
    "\n",
    "            # Complete path to save the figure\n",
    "            save_path_complete = f\"../datasets/{save_path}/state_variables/{state_variable}\"\n",
    "\n",
    "            # Check if image folder exists\n",
    "            if not os.path.exists(save_path_complete):\n",
    "                os.makedirs(save_path_complete)\n",
    "\n",
    "            # Save the figure\n",
    "            fig.savefig(save_path_complete + f\"/{state_variable}_{l}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95712d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Functions (Subgrid variables) --\n",
    "#\n",
    "# Allows to display easily an image (from coarsening notebook, version 2 with axis label)\n",
    "def imshow_2(arr, vlim = 3e-5):\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    plt.xlabel(\"Grid coordinates ($\\mathbb{R}$) - $x$ direction\")\n",
    "    return plt.imshow(arr, vmin = -vlim, vmax = vlim, cmap = 'bwr', interpolation = 'none')\n",
    "\n",
    "def plotPowerSpectrum(model_lr, forcing_variable = \"q\", save_path = \"\"):\n",
    "\n",
    "        # Power spectrum of subgrid potential vorticity\n",
    "        fig = plt.figure(figsize=(15, 4))\n",
    "        plt.title(f\"Power spectrum of $S_{forcing_variable}$\")\n",
    "\n",
    "        # Retreiving results\n",
    "        Sq = model_lr.subgrid_forcing('q')\n",
    "\n",
    "        # Applying fast fourier transform\n",
    "        line = plt.loglog(*calc_ispec(model_lr.m2, np.abs(model_lr.m2.fft(Sq))[0]**2), label = \"Low Resolution\")\n",
    "        plt.loglog(*calc_ispec(model_lr.m2, np.abs(model_lr.m2.fft(Sq))[1]**2), color=line[0]._color, ls='--', label='Low Resolution - (Lower bound)')\n",
    "        plt.legend(ncol=3)\n",
    "        plt.grid()\n",
    "        plt.ylabel(\"Power spectrum\")\n",
    "        plt.xlabel(\"Isotropic wavenumber - $\\lambda$\")\n",
    "\n",
    "        if save_path not in [\"\"]:\n",
    "\n",
    "            # Complete path to save the figure\n",
    "            save_path_complete = f\"../datasets/{save_path}/subgrid_forcing/power_spectrum/{forcing_variable}\"\n",
    "\n",
    "            # Check if image folder exists\n",
    "            if not os.path.exists(save_path_complete):\n",
    "                os.makedirs(save_path_complete)\n",
    "\n",
    "            # Save the figure\n",
    "            fig.savefig(save_path_complete + f\"/ps_{forcing_variable}.png\")\n",
    "\n",
    "def plotForcingVariable(model_lr, forcing_variable = \"sq\", save_path = \"\"):\n",
    "\n",
    "    # Subgrid - Potential vorticity\n",
    "    if forcing_variable == \"sq\":\n",
    "\n",
    "        # Initialization of the figure\n",
    "        fig = plt.figure(figsize=(22, 6))\n",
    "        plt.subplot(1, 2, 1, title = '$S_{q_{total}}$')\n",
    "        plt.ylabel(\"Grid coordinates ($\\mathbb{R}$) - $y$ direction\")\n",
    "\n",
    "        # Total potential vorticity forcing term (Sq_tot)\n",
    "        imshow_2(model_lr.q_forcing_total[0][0], 3e-11)\n",
    "\n",
    "        # Subgrid potential vorticity term (Sq)\n",
    "        plt.subplot(1, 2, 2, title = '$S_{q}$')\n",
    "        im = imshow_2(model_lr.subgrid_forcing('q')[0], 3e-11)\n",
    "        cb = fig.colorbar(im, ax = fig.axes, pad=0.15).set_label('$S_{q}$ [$s^{-2}$]')\n",
    "\n",
    "\n",
    "    # Subgrid - Horizontal velocity\n",
    "    if forcing_variable == \"su\":\n",
    "\n",
    "        # Initialization of the figure\n",
    "        fig = plt.figure(figsize=(22, 6))\n",
    "        plt.plot(title = '$S_{u}$')\n",
    "        plt.ylabel(\"Grid coordinates ($\\mathbb{R}$) - $y$ direction\")\n",
    "\n",
    "        # Subgrid potential vorticity term (Sq)\n",
    "        im = imshow_2(model_lr.subgrid_forcing('u')[0], 1.5e-7)\n",
    "        cb = fig.colorbar(im, ax = fig.axes, pad=0.15).set_label('$S_{u}$ [$m\\,s^{-2}$]')\n",
    "\n",
    "\n",
    "    # Subgrid - Vorticity flux\n",
    "    if forcing_variable == \"flux\":\n",
    "\n",
    "        # Initialization of the figure\n",
    "        fig = plt.figure(figsize=(22, 6))\n",
    "        plt.subplot(1, 2, 1, title = '$\\phi_{q_{u}}$')\n",
    "        plt.ylabel(\"Grid coordinates ($\\mathbb{R}$) - $y$ direction\")\n",
    "\n",
    "        # Retreiving fluxes\n",
    "        uq, vq = model_lr.subgrid_fluxes('q')\n",
    "\n",
    "        # Subgrid vorticity flux in horizontal direction\n",
    "        imshow_2(uq[1], 1.5e-8)\n",
    "\n",
    "        # Subgrid vorticity flux in vertical direction\n",
    "        plt.subplot(1, 2, 2, title = '$\\phi_{q_{v}}$')\n",
    "        im = imshow_2(vq[1], 1.5e-7)\n",
    "        cb = fig.colorbar(im, ax = fig.axes, pad=0.15).set_label('$\\phi_{q}$ [$m\\,s^{-2}$]')\n",
    "\n",
    "    if save_path not in [\"\"]:\n",
    "\n",
    "        # Complete path to save the figure\n",
    "        save_path_complete = f\"../datasets/{save_path}/subgrid_forcing/forcing_variable/{forcing_variable}\"\n",
    "\n",
    "        # Check if image folder exists\n",
    "        if not os.path.exists(save_path_complete):\n",
    "            os.makedirs(save_path_complete)\n",
    "\n",
    "        # Save the figure\n",
    "        fig.savefig(save_path_complete + f\"/fv_{forcing_variable}.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a55b66ee",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "<p align=\"center\">\n",
    "\t<b style=\"font-size:1vw;\">\n",
    "\tState variables\n",
    "\t</b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b8b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Potential vorticity q -- \n",
    "plotStateVariable(train_HR, train_LR, state_variable = \"q\", save_path = loading_folder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e849bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Horizontal velocity u -- \n",
    "plotStateVariable(train_HR, train_LR, state_variable = \"u\", save_path = loading_folder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e58c76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Vertical velocity v -- \n",
    "plotStateVariable(train_HR, train_LR, state_variable = \"v\", save_path = loading_folder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121b21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Horizontal velocity with background flow ufull -- \n",
    "plotStateVariable(train_HR, train_LR, state_variable = \"ufull\", save_path = loading_folder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Vertical velocity with background flow vfull -- \n",
    "plotStateVariable(train_HR, train_LR, state_variable = \"vfull\", save_path = loading_folder_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c57dd8c",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "<p align=\"center\">\n",
    "\t<b style=\"font-size:1vw;\">\n",
    "\tSubgrid variables\n",
    "\t</b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Potential vorticity --\n",
    "try   : \n",
    "    model_LOW_RESOLUTION\n",
    "except: \n",
    "    NameError: print(\"Attention : In order to display subgrid variables, you need the low resolution model !\")\n",
    "else  :\n",
    "    plotPowerSpectrum(  model_LOW_RESOLUTION, forcing_variable = \"q\",  save_path = loading_folder_data)\n",
    "    plotForcingVariable(model_LOW_RESOLUTION, forcing_variable = \"sq\", save_path = loading_folder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeb3fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Velocity --\n",
    "try   : \n",
    "    model_LOW_RESOLUTION\n",
    "except: \n",
    "    NameError: print(\"Attention : In order to display subgrid variables, you need the low resolution model !\")\n",
    "else  :\n",
    "    plotPowerSpectrum(  model_LOW_RESOLUTION, forcing_variable = \"u\",  save_path = loading_folder_data)\n",
    "    plotForcingVariable(model_LOW_RESOLUTION, forcing_variable = \"su\", save_path = loading_folder_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b98e10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Vorticity flux --\n",
    "try   : \n",
    "    model_LOW_RESOLUTION\n",
    "except: \n",
    "    NameError: print(\"Attention : In order to display subgrid variables, you need the low resolution model !\")\n",
    "else  :\n",
    "    plotForcingVariable(model_LOW_RESOLUTION, forcing_variable = \"flux\", save_path = loading_folder_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23045859",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#5A7D9F;\">\n",
    "    Fully Convolutional Neural Network (FCNN)\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "</p>\n",
    " \n",
    "- Create a new fully convolutional neural network based on the class FCNN created by L. Zanne & Al;\n",
    "\n",
    "- Train the network on the dataset created in the former section;\n",
    "\n",
    "- Save it for later use.\n",
    "\n",
    "*Note*\n",
    "\n",
    "- If you desire to experiment with the **architecture of the FCNN**, you can change it in the file *neural_network.py* starting at line 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c846c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the folder to store the resulting network\n",
    "result_folder = \"fcnn_q_to_Sqtot1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Functions --\n",
    "#\n",
    "# Used to determine the path to the results' folder\n",
    "def getPath(folder_name, loading = False):\n",
    "\n",
    "    # Count number of already existing folders in the model folder\n",
    "    nb_files = len(glob.glob(\"../models/*\"))\n",
    "\n",
    "    # Creation of a non-existing folder name\n",
    "    return f\"../models/{folder_name}/\" if loading else f\"../models/{folder_name}_{nb_files}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6b795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Training & Saving --\n",
    "#\n",
    "# Determine the complete path of the result folder\n",
    "result_folder_path = getPath(result_folder)\n",
    "\n",
    "# Training the parameterization\n",
    "FCNN_trained = FCNNParameterization.train_on(dataset    = train_LR, \n",
    "                                             directory  = result_folder_path,\n",
    "                                             inputs     = ['q', 'u', 'v'],\n",
    "                                             targets    = ['q_subgrid_forcing'],\n",
    "                                             num_epochs = 1, \n",
    "                                             zero_mean  = True, \n",
    "                                             padding    = 'circular')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c28f814",
   "metadata": {},
   "source": [
    "[comment]: <> (Section)\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "<p align=\"center\">\n",
    "    <b style=\"font-size:1.5vw; color:#5A7D9F;\">\n",
    "    FCCN - Parameterization evaluation (Offline & Online)\n",
    "    </b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F;\">\n",
    "\n",
    "[comment]: <> (Description)\n",
    "<p align=\"justify\">\n",
    "    In this section, one will be able to:\n",
    "</p>\n",
    " \n",
    "- **Load** a trained FCNN parameterization;\n",
    "\n",
    "- Evaluate its **offline performances** on a test set, i.e. it's ability to **predict** accurately the **subgrid forcing terms**;\n",
    "\n",
    "- Evaluate its **online performances** on a test set, i.e. it's ability to **create a ALRS** or in other words a simulation whose **results** are **close to** one obtained from a **high resolution simulation**.\n",
    "\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "<p align=\"center\">\n",
    "\t<b style=\"font-size:1vw;\">\n",
    "\tLoading a trained network\n",
    "\t</b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the folder that is used to load the neural network\n",
    "loading_folder = \"fcnn_q_to_Sqtot1\"\n",
    "\n",
    "# Define which target variable the network has been trained on (q_subgrid_forcing = 0 or q_forcing_total = 1)\n",
    "target_var = 1\n",
    "\n",
    "# Determine the complete path of the loading folder\n",
    "loading_folder_path = getPath(loading_folder, loading = True)\n",
    "\n",
    "# Loading the corresponding FCNN\n",
    "FCNN_trained = FCNNParameterization(loading_folder_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3da9f730",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "<p align=\"center\">\n",
    "\t<b style=\"font-size:1vw;\">\n",
    "\tOffline\n",
    "\t</b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "The two metrics used to evaluate the offline performances of the parameterization are:\n",
    "\n",
    "- **Pearson correlation** ($\\rho$) : where $\\sigma$ denotes the empirical standard deviation of a quantity over the dataset. This quantity is between -1 and 1 and can remain high even when R2 is negative, e.g. if predictions are wrong by a large but consistent scaling factor. It's mathematical expression is:\n",
    "\n",
    "$$\\rho = \\dfrac{\\text{Cov}(S, \\hat{S})}{\\sigma_S \\sigma_{\\hat{S}}}$$\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Coefficient of determination** ($R^2$) : which is 1 when predictions are perfect, 0 when predictions are no better than than always predicting the mean, and negative when worse than always predicting the mean. It's mathematical expression is:\n",
    "\n",
    "$$R^2 = 1 - \\dfrac{E[(S - \\hat{S})^2]}{E[(S - E[S])^2]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a124927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Functions --\n",
    "#\n",
    "# Used to plot easily the results\n",
    "def imshow(arr):\n",
    "    plt.imshow(arr, vmin = 0, vmax = 1, cmap = 'inferno')\n",
    "    mean = arr.mean().data\n",
    "    plt.text(32, 32, f\"{mean:.2f}\", color = ('white' if mean < 0.75 else 'black'),\n",
    "             fontweight = 'bold', ha = 'center', va = 'center', fontsize=16)\n",
    "    plt.xticks([]); plt.yticks([])\n",
    "    \n",
    "def colorbar(label):\n",
    "    plt.colorbar().set_label(label, fontsize=16,rotation=0,ha='left',va='center')\n",
    "\n",
    "def getDatasetAttributes(dataset):\n",
    "\n",
    "    # Retreives all the attributes\n",
    "    attributes = {}\n",
    "\n",
    "    # Constructing new attr\n",
    "    for k, v in dataset.attrs.items():\n",
    "        \n",
    "        # Updating string\n",
    "        updt_k = k.replace('pyqg:', '')\n",
    "\n",
    "        # Updating attribute dictionnary with correct parameters\n",
    "        if k in [\"nx\", \"dt\", \"tmax\", \"tavestart\", \"rek\", \"delta\", \"beta\"]:\n",
    "            attributes[k] = v\n",
    "\n",
    "    return attributes.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ee8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Computing predictions, plotting and saving offline tests results --\n",
    "#\n",
    "# Computing the predictions made by the parameterization\n",
    "offline_pred = FCNN_trained.test_offline(test_LR)\n",
    "\n",
    "# Plotting the results\n",
    "fig = plt.figure(figsize = (8, 6))\n",
    "\n",
    "# Adding title\n",
    "plt.suptitle(f\"Offline performance - {loading_folder}\")\n",
    "\n",
    "for z in [0, 1]:\n",
    "    plt.subplot(2, 2, z + 1, title = f\"{['Upper','Lower'][z]} layer\")\n",
    "    imshow(offline_pred.q_subgrid_forcing_spatial_correlation.isel(lev = z)) if target_var == 0 else \\\n",
    "    imshow(offline_pred.q_forcing_total_spatial_correlation.isel(lev = z))\n",
    "    if z: colorbar(\"ρ\")\n",
    "    \n",
    "for z in [0, 1]:\n",
    "    plt.subplot(2, 2, z + 3)\n",
    "    imshow(offline_pred.q_subgrid_forcing_spatial_skill.isel(lev = z)) if target_var == 0 else \\\n",
    "    imshow(offline_pred.q_forcing_total_spatial_skill.isel(lev = z))\n",
    "    if z: colorbar(\"$R^2$\")\n",
    "\n",
    "# Complete path to save the figure\n",
    "offline_path = f\"../datasets/{loading_folder_data}/offline/\"\n",
    "\n",
    "# Check if image folder exists\n",
    "if not os.path.exists(offline_path):\n",
    "    os.makedirs(offline_path)\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(offline_path + f\"/{loading_folder}.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e99b19f2",
   "metadata": {},
   "source": [
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">\n",
    "<p align=\"center\">\n",
    "\t<b style=\"font-size:1vw;\">\n",
    "\tOnline (GPU)\n",
    "\t</b>\n",
    "</p>\n",
    "<hr style=\"color:#5A7D9F; width: 100%;\" align=\"left\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8368011f",
   "metadata": {},
   "source": [
    "In this section, the goal is to test the **ability of the network to make good predictions** by checking the **physics** of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26debf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Computing predictions --\n",
    "#\n",
    "#online_preds = FCNN_trained.run_online(**getDatasetAttributes(test_LR))\n",
    "\n",
    "# Storing simulation results\n",
    "online_simulation = [(test_HR, 'High-res'),(test_LR, 'Low-res'), (online_preds,'Low-res + FCNN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49392eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Energy Budget Comparison --\n",
    "fig = energy_budget_figure(online_simulation)\n",
    "fig.suptitle(f\"Energy Budget Comparison - {loading_folder} - {loading_folder_data}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Complete path to save the figure\n",
    "online_path = f\"../datasets/{loading_folder_data}/online/\"\n",
    "\n",
    "# Check if image folder exists\n",
    "if not os.path.exists(online_path):\n",
    "    os.makedirs(online_path)\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(online_path + f\"/energy_budget.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359f08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Upper Potential Vorticity Comparison --\n",
    "fig = plt.figure(figsize = (13, 4))\n",
    "plt.suptitle(f\"Upper Potential Vorticity - {loading_folder} - {loading_folder_data}\")\n",
    "\n",
    "for i, (m, label) in enumerate(online_simulation):\n",
    "    plt.subplot(1, 3, i + 1, title = label)\n",
    "    plt.imshow(m.q.isel(lev = 0, time = -1), cmap='bwr', vmin = -3e-5, vmax = 3e-5)\n",
    "plt.colorbar(label=\"Upper PV [$s^{-1}$]\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Complete path to save the figure\n",
    "online_path = f\"../datasets/{loading_folder_data}/online/\"\n",
    "\n",
    "# Check if image folder exists\n",
    "if not os.path.exists(online_path):\n",
    "    os.makedirs(online_path)\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(online_path + f\"/PV_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Vorticity Distribution Comparison (Quasi Steady-State) --\n",
    "fig = fig = plt.figure()\n",
    "plt.title(f\"Differences in distributions of quasi-steady $q_1$ - {loading_folder} - {loading_folder_data}\")\n",
    "for i, (m, label) in enumerate(online_simulation):\n",
    "    data = m.q.isel(lev = 0, time = slice(-20, None)).data.ravel()\n",
    "    dist = gaussian_kde(data)\n",
    "    x = np.linspace(*np.percentile(data, [1,99]), 1000)\n",
    "    plt.plot(x, dist(x), label = label, lw = 3, ls = ('--' if 'FCNN' in label else '-'))\n",
    "plt.legend()\n",
    "plt.xlabel(\"Upper PV [$s^{-1}$]\")\n",
    "plt.ylabel(\"Probability density\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Complete path to save the figure\n",
    "online_path = f\"../datasets/{loading_folder_data}/online/\"\n",
    "\n",
    "# Check if image folder exists\n",
    "if not os.path.exists(online_path):\n",
    "    os.makedirs(online_path)\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig(online_path + f\"/distribution.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6970a6b860234838f15385a694e4c719e6911821bb317b2dd9580ae5d017ecf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
